{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from pyntcloud import PyntCloud\n",
    "\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from laserscan import LaserScan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner = LaserScan(project=True)\n",
    "scanner.open_scan(\"000000.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        ...,\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "       [[-2.5672e+01,  2.0000e-03,  1.0770e+00],\n",
       "        [-2.5897e+01,  2.0500e-01,  1.0850e+00],\n",
       "        [-2.6061e+01,  3.7000e-01,  1.0900e+00],\n",
       "        ...,\n",
       "        [-2.5239e+01, -3.9400e-01,  1.0630e+00],\n",
       "        [-2.5427e+01, -2.3700e-01,  1.0690e+00],\n",
       "        [-2.5588e+01, -7.8000e-02,  1.0740e+00]],\n",
       "\n",
       "       [[-2.5641e+01,  4.2000e-02,  9.1300e-01],\n",
       "        [-2.5798e+01,  2.0500e-01,  9.1800e-01],\n",
       "        [-2.5958e+01,  3.6900e-01,  9.2200e-01],\n",
       "        ...,\n",
       "        [-2.5507e+01, -3.4600e-01,  7.8900e-01],\n",
       "        [-2.5566e+01, -1.5900e-01,  9.1100e-01],\n",
       "        [-2.5497e+01, -7.8000e-02,  9.0900e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        ...,\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "       [[-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        ...,\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00]],\n",
       "\n",
       "       [[-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        ...,\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00],\n",
       "        [-1.0000e+00, -1.0000e+00, -1.0000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.proj_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [ 994,  991,  989, ...,  999,  997,  995],\n",
       "       [2920, 2918, 2916, ..., 4790, 2923, 2922],\n",
       "       ...,\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.proj_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.proj_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1024, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner.proj_xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Fire(nn.Module):\n",
    "  def __init__(self, inplanes, squeeze_planes,\n",
    "               expand1x1_planes, expand3x3_planes, bn_d=0.1):\n",
    "    super(Fire, self).__init__()\n",
    "    self.inplanes = inplanes\n",
    "    self.bn_d = bn_d\n",
    "    self.activation = nn.ReLU(inplace=True)\n",
    "    self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "    self.squeeze_bn = nn.BatchNorm2d(squeeze_planes, momentum=self.bn_d)\n",
    "    self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                               kernel_size=1)\n",
    "    self.expand1x1_bn = nn.BatchNorm2d(expand1x1_planes, momentum=self.bn_d)\n",
    "    self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                               kernel_size=3, padding=1)\n",
    "    self.expand3x3_bn = nn.BatchNorm2d(expand3x3_planes, momentum=self.bn_d)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.activation(self.squeeze_bn(self.squeeze(x)))\n",
    "    return torch.cat([\n",
    "        self.activation(self.expand1x1_bn(self.expand1x1(x))),\n",
    "        self.activation(self.expand3x3_bn(self.expand3x3(x)))\n",
    "    ], 1)\n",
    "\n",
    "\n",
    "class CAM(nn.Module):\n",
    "\n",
    "  def __init__(self, inplanes, bn_d=0.1):\n",
    "    super(CAM, self).__init__()\n",
    "    self.inplanes = inplanes\n",
    "    self.bn_d = bn_d\n",
    "    self.pool = nn.MaxPool2d(7, 1, 3)\n",
    "    self.squeeze = nn.Conv2d(inplanes, inplanes // 16,\n",
    "                             kernel_size=1, stride=1)\n",
    "    self.squeeze_bn = nn.BatchNorm2d(inplanes // 16, momentum=self.bn_d)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.unsqueeze = nn.Conv2d(inplanes // 16, inplanes,\n",
    "                               kernel_size=1, stride=1)\n",
    "    self.unsqueeze_bn = nn.BatchNorm2d(inplanes, momentum=self.bn_d)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # 7x7 pooling\n",
    "    y = self.pool(x)\n",
    "    # squeezing and relu\n",
    "    y = self.relu(self.squeeze_bn(self.squeeze(y)))\n",
    "    # unsqueezing\n",
    "    y = self.sigmoid(self.unsqueeze_bn(self.unsqueeze(y)))\n",
    "    # attention\n",
    "    return y * x\n",
    "\n",
    "# ******************************************************************************\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  \"\"\"\n",
    "     Class for Squeezeseg. Subclasses PyTorch's own \"nn\" module\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, params):\n",
    "    # Call the super constructor\n",
    "    super(Encoder, self).__init__()\n",
    "    print(\"Using SqueezeNet Backbone\")\n",
    "    self.use_range = params[\"input_depth\"][\"range\"]\n",
    "    self.use_xyz = params[\"input_depth\"][\"xyz\"]\n",
    "    self.use_remission = params[\"input_depth\"][\"remission\"]\n",
    "    self.extra_dim = params[\"input_depth\"][\"extra_dim\"]\n",
    "    self.extra_dim_num = params[\"input_depth\"][\"extra_dim_num\"]\n",
    "    self.bn_d = params[\"bn_d\"]\n",
    "    self.drop_prob = params[\"dropout\"]\n",
    "    self.OS = params[\"OS\"]\n",
    "\n",
    "    # input depth calc\n",
    "    self.input_depth = 0\n",
    "    self.input_idxs = []\n",
    "    if self.use_range:\n",
    "      self.input_depth += 1\n",
    "      self.input_idxs.append(0)\n",
    "    if self.use_xyz:\n",
    "      self.input_depth += 3\n",
    "      self.input_idxs.extend([1, 2, 3])\n",
    "    if self.extra_dim:\n",
    "      print(\"True dim\")\n",
    "      self.input_depth += self.extra_dim_num\n",
    "      self.input_idxs.extend([each for each in range(3, self.extra_dim_num+3)])\n",
    "      print(self.input_idxs)\n",
    "    if self.use_remission:\n",
    "      self.input_depth += 1\n",
    "      self.input_idxs.append(len(self.input_idxs))\n",
    "\n",
    "    print(\"Depth of backbone input = \", self.input_depth)\n",
    "\n",
    "    # stride play\n",
    "    self.strides = [2, 2, 2, 2]\n",
    "    # check current stride\n",
    "    current_os = 1\n",
    "    for s in self.strides:\n",
    "      current_os *= s\n",
    "    print(\"Original OS: \", current_os)\n",
    "\n",
    "    # make the new stride\n",
    "    if self.OS > current_os:\n",
    "      print(\"Can't do OS, \", self.OS,\n",
    "            \" because it is bigger than original \", current_os)\n",
    "    else:\n",
    "      # redo strides according to needed stride\n",
    "      for i, stride in enumerate(reversed(self.strides), 0):\n",
    "        if int(current_os) != self.OS:\n",
    "          if stride == 2:\n",
    "            current_os /= 2\n",
    "            self.strides[-1 - i] = 1\n",
    "          if int(current_os) == self.OS:\n",
    "            break\n",
    "      print(\"New OS: \", int(current_os))\n",
    "      print(\"Strides: \", self.strides)\n",
    "    print(\"input depth is \", self.input_depth)\n",
    "    # encoder\n",
    "    self.conv1a = nn.Sequential(nn.Conv2d(self.input_depth, 64, kernel_size=3,\n",
    "                                          stride=[1, self.strides[0]],\n",
    "                                          padding=1),\n",
    "                                nn.BatchNorm2d(64, momentum=self.bn_d),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                CAM(64, bn_d=self.bn_d))\n",
    "    self.conv1b = nn.Sequential(nn.Conv2d(self.input_depth, 64, kernel_size=1,\n",
    "                                          stride=1, padding=0),\n",
    "                                nn.BatchNorm2d(64, momentum=self.bn_d))\n",
    "    self.fire23 = nn.Sequential(nn.MaxPool2d(kernel_size=3,\n",
    "                                             stride=[1, self.strides[1]],\n",
    "                                             padding=1),\n",
    "                                Fire(64, 16, 64, 64, bn_d=self.bn_d),\n",
    "                                CAM(128, bn_d=self.bn_d),\n",
    "                                Fire(128, 16, 64, 64, bn_d=self.bn_d),\n",
    "                                CAM(128, bn_d=self.bn_d))\n",
    "    self.fire45 = nn.Sequential(nn.MaxPool2d(kernel_size=3,\n",
    "                                             stride=[1, self.strides[2]],\n",
    "                                             padding=1),\n",
    "                                Fire(128, 32, 128, 128, bn_d=self.bn_d),\n",
    "                                Fire(256, 32, 128, 128, bn_d=self.bn_d))\n",
    "    self.fire6789 = nn.Sequential(nn.MaxPool2d(kernel_size=3,\n",
    "                                               stride=[1, self.strides[3]],\n",
    "                                               padding=1),\n",
    "                                  Fire(256, 48, 192, 192, bn_d=self.bn_d),\n",
    "                                  Fire(384, 48, 192, 192, bn_d=self.bn_d),\n",
    "                                  Fire(384, 64, 256, 256, bn_d=self.bn_d),\n",
    "                                  Fire(512, 64, 256, 256, bn_d=self.bn_d))\n",
    "\n",
    "    self._conv1 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(\n",
    "\t\t\t\tin_channels=512, out_channels=256, kernel_size=2, stride=2\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "    # output\n",
    "    self.dropout = nn.Dropout2d(self.drop_prob)\n",
    "\n",
    "    # last channels\n",
    "    self.last_channels = 512\n",
    "\n",
    "  def run_layer(self, x, layer, skips, os):\n",
    "    y = layer(x)\n",
    "    if y.shape[2] < x.shape[2] or y.shape[3] < x.shape[3]:\n",
    "      skips[os] = x.detach()\n",
    "      os *= 2\n",
    "    x = y\n",
    "    return x, skips, os\n",
    "\n",
    "  def forward(self, x):\n",
    "    # filter input\n",
    "#     print(\"before filtering \", x.shape)\n",
    "    x = x[:, self.input_idxs]\n",
    "\n",
    "    # run cnn\n",
    "    # store for skip connections\n",
    "    skips = {}\n",
    "    os = 1\n",
    "    print(\"/\"*30, \" starting encoder \",\"/\"*30)\n",
    "    print(\"input shape \",x.shape)\n",
    "    x = x.float()\n",
    "    # encoder\n",
    "    skip_in = self.conv1b(x)\n",
    "    x = self.conv1a(x)\n",
    "    # first skip done manually\n",
    "    skips[1] = skip_in.detach()\n",
    "    os *= 2\n",
    "\n",
    "    x, skips, os = self.run_layer(x, self.fire23, skips, os)\n",
    "    print(\"fire23 shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.dropout, skips, os)\n",
    "    print(\"dropout shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.fire45, skips, os)\n",
    "    print(\"fire45 shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.dropout, skips, os)\n",
    "    print(\"dropout shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.fire6789, skips, os)\n",
    "    print(\"fire6789 shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.dropout, skips, os)\n",
    "    print(\"dropout shape \", x.size())\n",
    "\n",
    "    return x, skips\n",
    "\n",
    "  def get_last_depth(self):\n",
    "    return self.last_channels\n",
    "\n",
    "  def get_input_depth(self):\n",
    "    return self.input_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireUp(nn.Module):\n",
    "\n",
    "  def __init__(self, inplanes, squeeze_planes,\n",
    "               expand1x1_planes, expand3x3_planes, bn_d, stride):\n",
    "    super(FireUp, self).__init__()\n",
    "    self.inplanes = inplanes\n",
    "    self.bn_d = bn_d\n",
    "    self.stride = stride\n",
    "    self.activation = nn.ReLU(inplace=True)\n",
    "    self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "    self.squeeze_bn = nn.BatchNorm2d(squeeze_planes, momentum=self.bn_d)\n",
    "    if self.stride == 2:\n",
    "      self.upconv = nn.ConvTranspose2d(squeeze_planes, squeeze_planes,\n",
    "                                       kernel_size=[1, 4], stride=[1, 2],\n",
    "                                       padding=[0, 1])\n",
    "    self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                               kernel_size=1)\n",
    "    self.expand1x1_bn = nn.BatchNorm2d(expand1x1_planes, momentum=self.bn_d)\n",
    "    self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                               kernel_size=3, padding=1)\n",
    "    self.expand3x3_bn = nn.BatchNorm2d(expand3x3_planes, momentum=self.bn_d)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.activation(self.squeeze_bn(self.squeeze(x)))\n",
    "    if self.stride == 2:\n",
    "      x = self.activation(self.upconv(x))\n",
    "    return torch.cat([\n",
    "        self.activation(self.expand1x1_bn(self.expand1x1(x))),\n",
    "        self.activation(self.expand3x3_bn(self.expand3x3(x)))\n",
    "    ], 1)\n",
    "\n",
    "\n",
    "# ******************************************************************************\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  \"\"\"\n",
    "     Class for DarknetSeg. Subclasses PyTorch's own \"nn\" module\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, params, OS=32, feature_depth=512):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.backbone_OS = OS\n",
    "    self.backbone_feature_depth = feature_depth\n",
    "    self.drop_prob = params[\"dropout\"]\n",
    "    self.bn_d = params[\"bn_d\"]\n",
    "\n",
    "    # stride play\n",
    "    self.strides = [2, 2, 2, 2]\n",
    "    # check current stride\n",
    "    current_os = 1\n",
    "    for s in self.strides:\n",
    "      current_os *= s\n",
    "    print(\"Decoder original OS: \", int(current_os))\n",
    "    # redo strides according to needed stride\n",
    "    for i, stride in enumerate(self.strides):\n",
    "      if int(current_os) != self.backbone_OS:\n",
    "        if stride == 2:\n",
    "          current_os /= 2\n",
    "          self.strides[i] = 1\n",
    "        if int(current_os) == self.backbone_OS:\n",
    "          break\n",
    "    print(\"Decoder new OS: \", int(current_os))\n",
    "    print(\"Decoder strides: \", self.strides)\n",
    "\n",
    "    # decoder\n",
    "    # decoder\n",
    "    self.firedec10 = FireUp(self.backbone_feature_depth,\n",
    "                            64, 128, 128, bn_d=self.bn_d,\n",
    "                            stride=self.strides[0])\n",
    "    self.firedec11 = FireUp(256, 32, 64, 64, bn_d=self.bn_d,\n",
    "                            stride=self.strides[1])\n",
    "    self.firedec12 = FireUp(128, 16, 32, 32, bn_d=self.bn_d,\n",
    "                            stride=self.strides[2])\n",
    "    self.firedec13 = FireUp(64, 16, 32, 32, bn_d=self.bn_d,\n",
    "                            stride=self.strides[3])\n",
    "\n",
    "    # for a bit of fun\n",
    "    self.dropout = nn.Dropout2d(self.drop_prob)\n",
    "\n",
    "    # last channels\n",
    "    self.last_channels = 64\n",
    "    \n",
    "#     self._conv1 = nn.Sequential(\n",
    "#         nn.Conv2d(\n",
    "#             in_channels=512, out_channels=256, kernel_size=2, stride=2\n",
    "#         ))\n",
    "    \n",
    "#     self._conv2 = nn.Sequential(\n",
    "#         nn.Conv2d(\n",
    "#             in_channels=256, out_channels=128, kernel_size=2, stride=2\n",
    "#         ))\n",
    "#     self._conv3 = nn.Sequential(\n",
    "#         nn.Conv2d(\n",
    "#             in_channels=128, out_channels=96, kernel_size=2, stride=2\n",
    "#         ))\n",
    "    \n",
    "    self._conv1 = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=64, out_channels=32, kernel_size=6, stride=2\n",
    "        ))\n",
    "    \n",
    "\n",
    "\n",
    "  def run_layer(self, x, layer, skips, os):\n",
    "    feats = layer(x)  # up\n",
    "    if feats.shape[-1] > x.shape[-1]:\n",
    "      os //= 2  # match skip\n",
    "      feats = feats + skips[os].detach()  # add skip\n",
    "    x = feats\n",
    "    return x, skips, os\n",
    "\n",
    "  def forward(self, x, skips):\n",
    "    print(\"/\"*30, \" starting decoder \",\"/\"*30)\n",
    "    os = self.backbone_OS\n",
    "    print(\"input shape \", x.size())\n",
    "    # run layers\n",
    "    x, skips, os = self.run_layer(x, self.firedec10, skips, os)\n",
    "    print(\"firedec10 shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.firedec11, skips, os)\n",
    "    print(\"firedec11 shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.firedec12, skips, os)\n",
    "    print(\"firedec12 shape \", x.size())\n",
    "    x, skips, os = self.run_layer(x, self.firedec13, skips, os)\n",
    "    print(\"firedec13 shape \", x.size())\n",
    "    \n",
    "#     out = self._conv1(x) # reduce dim 64 -> 32, channels 64 -> 32\n",
    "#     out = self._conv2(out) # k=2, s=1. reduce dim 32 -> 30, channels 32 -> 32\n",
    "    x = self._conv1(x) # k=6, s=2, reduce dim 64 -> 30, channels 64 -> 32\n",
    "#     x = self.dropout(x)\n",
    "    print(\"output shape \", x.size())\n",
    "    return x\n",
    "\n",
    "  def get_last_depth(self):\n",
    "    return self.last_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SqueezeNet Backbone\n",
      "True dim\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "Depth of backbone input =  6\n",
      "Original OS:  16\n",
      "New OS:  16\n",
      "Strides:  [2, 2, 2, 2]\n",
      "input depth is  6\n",
      "Decoder original OS:  16\n",
      "Decoder new OS:  1\n",
      "Decoder strides:  [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "with open(\"config/arch/squeezesegV2.yaml\", 'r') as pnt:\n",
    "    ARCH = yaml.safe_load(pnt)\n",
    "encoder_model = Encoder(ARCH[\"backbone\"])\n",
    "decoder_model = Decoder(ARCH[\"backbone\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyz shape  torch.Size([1, 64, 1024, 3])\n",
      "range shape  torch.Size([1, 64, 1024])\n",
      "remission shape  torch.Size([1, 64, 1024])\n",
      "concat dim  torch.Size([1, 64, 1024, 5])\n"
     ]
    }
   ],
   "source": [
    "# prepare input with channel as last dim\n",
    "complete_data = scanner.proj_xyz[np.newaxis]\n",
    "complete_data_torch = torch.from_numpy(complete_data)\n",
    "print(\"xyz shape \",complete_data_torch.size())\n",
    "\n",
    "range_data = scanner.proj_range[np.newaxis]\n",
    "range_data_torch = torch.from_numpy(range_data)\n",
    "print(\"range shape \",range_data_torch.size())\n",
    "\n",
    "remission_data = scanner.proj_remission[np.newaxis]\n",
    "remission_data_torch = torch.from_numpy(remission_data)\n",
    "print(\"remission shape \",remission_data_torch.size())\n",
    "\n",
    "concat_data = torch.cat((complete_data_torch, range_data_torch.unsqueeze(3), remission_data_torch.unsqueeze(3)), dim=3)\n",
    "print(\"concat dim \", concat_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyz shape  torch.Size([1, 3, 64, 1024])\n",
      "range shape  torch.Size([1, 1, 64, 1024])\n",
      "remission shape  torch.Size([1, 1, 64, 1024])\n",
      "concat dim  torch.Size([1, 6, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "# prepare input with channel in dim=2\n",
    "complete_data = scanner.proj_xyz[np.newaxis]\n",
    "complete_data_torch = torch.from_numpy(complete_data)\n",
    "complete_data_torch = torch.transpose(complete_data_torch, 1, 3)\n",
    "complete_data_torch = torch.transpose(complete_data_torch, 2, 3)\n",
    "print(\"xyz shape \",complete_data_torch.size())\n",
    "\n",
    "range_data = scanner.proj_range[np.newaxis]\n",
    "range_data_torch = torch.from_numpy(range_data)\n",
    "range_data_torch = torch.transpose(range_data_torch.unsqueeze(3), 1, 3)\n",
    "range_data_torch = torch.transpose(range_data_torch, 2, 3)\n",
    "print(\"range shape \",range_data_torch.size())\n",
    "\n",
    "remission_data = scanner.proj_remission[np.newaxis]\n",
    "remission_data_torch = torch.from_numpy(remission_data)\n",
    "remission_data_torch = torch.transpose(remission_data_torch.unsqueeze(3), 1, 3)\n",
    "remission_data_torch = torch.transpose(remission_data_torch, 2, 3)\n",
    "print(\"remission shape \",remission_data_torch.size())\n",
    "\n",
    "concat_data = torch.cat((complete_data_torch, range_data_torch, remission_data_torch, remission_data_torch), dim=1)\n",
    "print(\"concat dim \", concat_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//////////////////////////////  starting encoder  //////////////////////////////\n",
      "input shape  torch.Size([1, 6, 64, 1024])\n",
      "fire23 shape  torch.Size([1, 128, 64, 256])\n",
      "dropout shape  torch.Size([1, 128, 64, 256])\n",
      "fire45 shape  torch.Size([1, 256, 64, 128])\n",
      "dropout shape  torch.Size([1, 256, 64, 128])\n",
      "fire6789 shape  torch.Size([1, 512, 64, 64])\n",
      "dropout shape  torch.Size([1, 512, 64, 64])\n",
      "//////////////////////////////  starting decoder  //////////////////////////////\n",
      "input shape  torch.Size([1, 512, 64, 64])\n",
      "firedec10 shape  torch.Size([1, 256, 64, 64])\n",
      "firedec11 shape  torch.Size([1, 128, 64, 64])\n",
      "firedec12 shape  torch.Size([1, 64, 64, 64])\n",
      "firedec13 shape  torch.Size([1, 64, 64, 64])\n",
      "output shape  torch.Size([1, 32, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# run through squeezeseg\n",
    "endoded, e_skips = encoder_model(concat_data)\n",
    "output = decoder_model(endoded, e_skips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 30, 30])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
